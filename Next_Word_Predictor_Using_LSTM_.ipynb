{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5mR0vlqI74K"
      },
      "outputs": [],
      "source": [
        "faqs = \"\"\"About Yash\n",
        "Who is Yash?\n",
        "Yash is a first-year college student who is deeply interested in AI, Data Science, and Machine Learning.\n",
        "\n",
        "What courses has Yash learned so far?\n",
        "Yash has completed C programming, basic Python, and is actively learning C++, DSA, Machine Learning, and Pandas.\n",
        "\n",
        "What are Yash’s long-term goals?\n",
        "Yash aims to pursue a career in Data Science and Machine Learning, and eventually build a startup.\n",
        "\n",
        "What are Yash’s current college roles?\n",
        "Yash has been selected for the Entrepreneurship Cell at DTU and is giving interviews for tech societies.\n",
        "\n",
        "What kind of projects is Yash working on?\n",
        "Yash works on projects related to document intelligence, carbon-emission alternatives, medical ethics, and mathematical assignments.\n",
        "\n",
        "Learning & Skills\n",
        "What programming languages does Yash know?\n",
        "Yash knows C, basic Python, and is learning C++ and DSA.\n",
        "\n",
        "What machine learning concepts has Yash learned?\n",
        "Yash understands basic ML algorithms, pandas, numpy, data preprocessing, and model evaluation (beginner-friendly level).\n",
        "\n",
        "Does Yash practice DSA daily?\n",
        "Yash is building the habit of practising DSA regularly and prefers detailed explanations.\n",
        "\n",
        "What are Yash’s strengths in learning?\n",
        "Yash loves practical explanations, wants deep theory, and prefers step-by-step breakdowns of concepts.\n",
        "\n",
        "Projects\n",
        "What major projects has Yash completed?\n",
        "Some of Yash’s projects include:\n",
        "Carbon tracking website\n",
        "Document intelligence engine prototype\n",
        "Medical ethics decision analysis based on the book “My Sister’s Keeper”\n",
        "Assignments in EVS, Physics, and Digital Logic\n",
        "\n",
        "What is Yash’s hackathon experience?\n",
        "Yash participated in his first hackathon where his team reached the top 50 out of 1600+ teams.\n",
        "\n",
        "What startup idea is Yash working on?\n",
        "Yash is thinking of launching a startup that provides verified home tutors.\n",
        "\n",
        "Academics & College\n",
        "What is Yash currently studying in college?\n",
        "Yash is studying C++, DSA foundations, Digital Logic, Applied Physics, Computational Methods, and EVS.\n",
        "\n",
        "What subjects does Yash need detailed notes for?\n",
        "Yash prefers deep notes for topics like pointers, crystal structure, arithmetic logic, instruction cycles, and memory hierarchy.\n",
        "\n",
        "Schedule & Habits\n",
        "How does Yash plan his day?\n",
        "Yash follows structured routines including ML lectures, DSA practice, breaks, coding sessions, and recap time.\n",
        "\n",
        "Does Yash like reminders?\n",
        "Yes, Yash sometimes asks ChatGPT to ask “Aaj DSA kra?” but then also says not to ask it.\n",
        "\n",
        "Technical Interests\n",
        "What is Yash most passionate about?\n",
        "Yash is passionate about AI, ML, DSA, and developing real-world projects.\n",
        "\n",
        "What type of explanations does Yash prefer?\n",
        "Yash prefers:\n",
        "Detailed\n",
        "Thorough\n",
        "Theory + examples\n",
        "Simple language\n",
        "No shortcuts\n",
        "\n",
        "Future Goals\n",
        "What does Yash want to achieve next year?\n",
        "Yash wants:\n",
        "To build stronger DSA foundations\n",
        "To complete ML roadmap\n",
        "To do more hackathons\n",
        "To grow his SMMA\n",
        "To work on a startup\n",
        "To improve consistency\n",
        "\n",
        "Personal Style\n",
        "What nickname does Yash prefer for ChatGPT?\n",
        "Yash likes to call ChatGPT “gippuu”.\n",
        "\n",
        "What type of help does Yash expect from ChatGPT?\n",
        "Yash expects:\n",
        "Clear explanations\n",
        "Fast solutions\n",
        "Code debugging\n",
        "Project guidance\n",
        "Assignments support\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "uEb-4eoMLnFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=Tokenizer()"
      ],
      "metadata": {
        "id": "A8y4uzRlMGvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([faqs])"
      ],
      "metadata": {
        "id": "x7tBYD9tMYpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJw00ugiMdFo",
        "outputId": "7f4c3073-1180-4c23-c387-50c06f1478a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'yash': 1,\n",
              " 'and': 2,\n",
              " 'what': 3,\n",
              " 'is': 4,\n",
              " 'to': 5,\n",
              " 'dsa': 6,\n",
              " 'does': 7,\n",
              " 'learning': 8,\n",
              " 'of': 9,\n",
              " 'in': 10,\n",
              " 'projects': 11,\n",
              " 'a': 12,\n",
              " 'has': 13,\n",
              " 'c': 14,\n",
              " 'yash’s': 15,\n",
              " 'for': 16,\n",
              " 'on': 17,\n",
              " 'college': 18,\n",
              " 'machine': 19,\n",
              " 'startup': 20,\n",
              " 'the': 21,\n",
              " 'ml': 22,\n",
              " 'prefers': 23,\n",
              " 'explanations': 24,\n",
              " 'his': 25,\n",
              " 'chatgpt': 26,\n",
              " 'about': 27,\n",
              " 'data': 28,\n",
              " 'basic': 29,\n",
              " 'are': 30,\n",
              " 'assignments': 31,\n",
              " 'detailed': 32,\n",
              " 'logic': 33,\n",
              " 'who': 34,\n",
              " 'first': 35,\n",
              " 'year': 36,\n",
              " 'ai': 37,\n",
              " 'science': 38,\n",
              " 'learned': 39,\n",
              " 'completed': 40,\n",
              " 'programming': 41,\n",
              " 'python': 42,\n",
              " 'pandas': 43,\n",
              " 'goals': 44,\n",
              " 'build': 45,\n",
              " 'working': 46,\n",
              " 'document': 47,\n",
              " 'intelligence': 48,\n",
              " 'carbon': 49,\n",
              " 'medical': 50,\n",
              " 'ethics': 51,\n",
              " 'concepts': 52,\n",
              " 'practice': 53,\n",
              " 'wants': 54,\n",
              " 'deep': 55,\n",
              " 'theory': 56,\n",
              " 'step': 57,\n",
              " 'evs': 58,\n",
              " 'physics': 59,\n",
              " 'digital': 60,\n",
              " 'hackathon': 61,\n",
              " 'studying': 62,\n",
              " 'foundations': 63,\n",
              " 'notes': 64,\n",
              " 'like': 65,\n",
              " 'ask': 66,\n",
              " 'passionate': 67,\n",
              " 'type': 68,\n",
              " 'prefer': 69,\n",
              " 'student': 70,\n",
              " 'deeply': 71,\n",
              " 'interested': 72,\n",
              " 'courses': 73,\n",
              " 'so': 74,\n",
              " 'far': 75,\n",
              " 'actively': 76,\n",
              " 'long': 77,\n",
              " 'term': 78,\n",
              " 'aims': 79,\n",
              " 'pursue': 80,\n",
              " 'career': 81,\n",
              " 'eventually': 82,\n",
              " 'current': 83,\n",
              " 'roles': 84,\n",
              " 'been': 85,\n",
              " 'selected': 86,\n",
              " 'entrepreneurship': 87,\n",
              " 'cell': 88,\n",
              " 'at': 89,\n",
              " 'dtu': 90,\n",
              " 'giving': 91,\n",
              " 'interviews': 92,\n",
              " 'tech': 93,\n",
              " 'societies': 94,\n",
              " 'kind': 95,\n",
              " 'works': 96,\n",
              " 'related': 97,\n",
              " 'emission': 98,\n",
              " 'alternatives': 99,\n",
              " 'mathematical': 100,\n",
              " 'skills': 101,\n",
              " 'languages': 102,\n",
              " 'know': 103,\n",
              " 'knows': 104,\n",
              " 'understands': 105,\n",
              " 'algorithms': 106,\n",
              " 'numpy': 107,\n",
              " 'preprocessing': 108,\n",
              " 'model': 109,\n",
              " 'evaluation': 110,\n",
              " 'beginner': 111,\n",
              " 'friendly': 112,\n",
              " 'level': 113,\n",
              " 'daily': 114,\n",
              " 'building': 115,\n",
              " 'habit': 116,\n",
              " 'practising': 117,\n",
              " 'regularly': 118,\n",
              " 'strengths': 119,\n",
              " 'loves': 120,\n",
              " 'practical': 121,\n",
              " 'by': 122,\n",
              " 'breakdowns': 123,\n",
              " 'major': 124,\n",
              " 'some': 125,\n",
              " 'include': 126,\n",
              " 'tracking': 127,\n",
              " 'website': 128,\n",
              " 'engine': 129,\n",
              " 'prototype': 130,\n",
              " 'decision': 131,\n",
              " 'analysis': 132,\n",
              " 'based': 133,\n",
              " 'book': 134,\n",
              " '“my': 135,\n",
              " 'sister’s': 136,\n",
              " 'keeper”': 137,\n",
              " 'experience': 138,\n",
              " 'participated': 139,\n",
              " 'where': 140,\n",
              " 'team': 141,\n",
              " 'reached': 142,\n",
              " 'top': 143,\n",
              " '50': 144,\n",
              " 'out': 145,\n",
              " '1600': 146,\n",
              " 'teams': 147,\n",
              " 'idea': 148,\n",
              " 'thinking': 149,\n",
              " 'launching': 150,\n",
              " 'that': 151,\n",
              " 'provides': 152,\n",
              " 'verified': 153,\n",
              " 'home': 154,\n",
              " 'tutors': 155,\n",
              " 'academics': 156,\n",
              " 'currently': 157,\n",
              " 'applied': 158,\n",
              " 'computational': 159,\n",
              " 'methods': 160,\n",
              " 'subjects': 161,\n",
              " 'need': 162,\n",
              " 'topics': 163,\n",
              " 'pointers': 164,\n",
              " 'crystal': 165,\n",
              " 'structure': 166,\n",
              " 'arithmetic': 167,\n",
              " 'instruction': 168,\n",
              " 'cycles': 169,\n",
              " 'memory': 170,\n",
              " 'hierarchy': 171,\n",
              " 'schedule': 172,\n",
              " 'habits': 173,\n",
              " 'how': 174,\n",
              " 'plan': 175,\n",
              " 'day': 176,\n",
              " 'follows': 177,\n",
              " 'structured': 178,\n",
              " 'routines': 179,\n",
              " 'including': 180,\n",
              " 'lectures': 181,\n",
              " 'breaks': 182,\n",
              " 'coding': 183,\n",
              " 'sessions': 184,\n",
              " 'recap': 185,\n",
              " 'time': 186,\n",
              " 'reminders': 187,\n",
              " 'yes': 188,\n",
              " 'sometimes': 189,\n",
              " 'asks': 190,\n",
              " '“aaj': 191,\n",
              " 'kra': 192,\n",
              " '”': 193,\n",
              " 'but': 194,\n",
              " 'then': 195,\n",
              " 'also': 196,\n",
              " 'says': 197,\n",
              " 'not': 198,\n",
              " 'it': 199,\n",
              " 'technical': 200,\n",
              " 'interests': 201,\n",
              " 'most': 202,\n",
              " 'developing': 203,\n",
              " 'real': 204,\n",
              " 'world': 205,\n",
              " 'thorough': 206,\n",
              " 'examples': 207,\n",
              " 'simple': 208,\n",
              " 'language': 209,\n",
              " 'no': 210,\n",
              " 'shortcuts': 211,\n",
              " 'future': 212,\n",
              " 'want': 213,\n",
              " 'achieve': 214,\n",
              " 'next': 215,\n",
              " 'stronger': 216,\n",
              " 'complete': 217,\n",
              " 'roadmap': 218,\n",
              " 'do': 219,\n",
              " 'more': 220,\n",
              " 'hackathons': 221,\n",
              " 'grow': 222,\n",
              " 'smma': 223,\n",
              " 'work': 224,\n",
              " 'improve': 225,\n",
              " 'consistency': 226,\n",
              " 'personal': 227,\n",
              " 'style': 228,\n",
              " 'nickname': 229,\n",
              " 'likes': 230,\n",
              " 'call': 231,\n",
              " '“gippuu”': 232,\n",
              " 'help': 233,\n",
              " 'expect': 234,\n",
              " 'from': 235,\n",
              " 'expects': 236,\n",
              " 'clear': 237,\n",
              " 'fast': 238,\n",
              " 'solutions': 239,\n",
              " 'code': 240,\n",
              " 'debugging': 241,\n",
              " 'project': 242,\n",
              " 'guidance': 243,\n",
              " 'support': 244}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for sentence in faqs.split('\\n'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1,len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[:i+1])\n"
      ],
      "metadata": {
        "id": "LEmtRieWMfuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFnD9PCUNHcG",
        "outputId": "a8fa3acf-17cb-44a6-d785-8ab4b8846728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[27, 1],\n",
              " [34, 4],\n",
              " [34, 4, 1],\n",
              " [1, 4],\n",
              " [1, 4, 12],\n",
              " [1, 4, 12, 35],\n",
              " [1, 4, 12, 35, 36],\n",
              " [1, 4, 12, 35, 36, 18],\n",
              " [1, 4, 12, 35, 36, 18, 70],\n",
              " [1, 4, 12, 35, 36, 18, 70, 34],\n",
              " [1, 4, 12, 35, 36, 18, 70, 34, 4],\n",
              " [1, 4, 12, 35, 36, 18, 70, 34, 4, 71],\n",
              " [1, 4, 12, 35, 36, 18, 70, 34, 4, 71, 72],\n",
              " [1, 4, 12, 35, 36, 18, 70, 34, 4, 71, 72, 10],\n",
              " [1, 4, 12, 35, 36, 18, 70, 34, 4, 71, 72, 10, 37],\n",
              " [1, 4, 12, 35, 36, 18, 70, 34, 4, 71, 72, 10, 37, 28],\n",
              " [1, 4, 12, 35, 36, 18, 70, 34, 4, 71, 72, 10, 37, 28, 38],\n",
              " [1, 4, 12, 35, 36, 18, 70, 34, 4, 71, 72, 10, 37, 28, 38, 2],\n",
              " [1, 4, 12, 35, 36, 18, 70, 34, 4, 71, 72, 10, 37, 28, 38, 2, 19],\n",
              " [1, 4, 12, 35, 36, 18, 70, 34, 4, 71, 72, 10, 37, 28, 38, 2, 19, 8],\n",
              " [3, 73],\n",
              " [3, 73, 13],\n",
              " [3, 73, 13, 1],\n",
              " [3, 73, 13, 1, 39],\n",
              " [3, 73, 13, 1, 39, 74],\n",
              " [3, 73, 13, 1, 39, 74, 75],\n",
              " [1, 13],\n",
              " [1, 13, 40],\n",
              " [1, 13, 40, 14],\n",
              " [1, 13, 40, 14, 41],\n",
              " [1, 13, 40, 14, 41, 29],\n",
              " [1, 13, 40, 14, 41, 29, 42],\n",
              " [1, 13, 40, 14, 41, 29, 42, 2],\n",
              " [1, 13, 40, 14, 41, 29, 42, 2, 4],\n",
              " [1, 13, 40, 14, 41, 29, 42, 2, 4, 76],\n",
              " [1, 13, 40, 14, 41, 29, 42, 2, 4, 76, 8],\n",
              " [1, 13, 40, 14, 41, 29, 42, 2, 4, 76, 8, 14],\n",
              " [1, 13, 40, 14, 41, 29, 42, 2, 4, 76, 8, 14, 6],\n",
              " [1, 13, 40, 14, 41, 29, 42, 2, 4, 76, 8, 14, 6, 19],\n",
              " [1, 13, 40, 14, 41, 29, 42, 2, 4, 76, 8, 14, 6, 19, 8],\n",
              " [1, 13, 40, 14, 41, 29, 42, 2, 4, 76, 8, 14, 6, 19, 8, 2],\n",
              " [1, 13, 40, 14, 41, 29, 42, 2, 4, 76, 8, 14, 6, 19, 8, 2, 43],\n",
              " [3, 30],\n",
              " [3, 30, 15],\n",
              " [3, 30, 15, 77],\n",
              " [3, 30, 15, 77, 78],\n",
              " [3, 30, 15, 77, 78, 44],\n",
              " [1, 79],\n",
              " [1, 79, 5],\n",
              " [1, 79, 5, 80],\n",
              " [1, 79, 5, 80, 12],\n",
              " [1, 79, 5, 80, 12, 81],\n",
              " [1, 79, 5, 80, 12, 81, 10],\n",
              " [1, 79, 5, 80, 12, 81, 10, 28],\n",
              " [1, 79, 5, 80, 12, 81, 10, 28, 38],\n",
              " [1, 79, 5, 80, 12, 81, 10, 28, 38, 2],\n",
              " [1, 79, 5, 80, 12, 81, 10, 28, 38, 2, 19],\n",
              " [1, 79, 5, 80, 12, 81, 10, 28, 38, 2, 19, 8],\n",
              " [1, 79, 5, 80, 12, 81, 10, 28, 38, 2, 19, 8, 2],\n",
              " [1, 79, 5, 80, 12, 81, 10, 28, 38, 2, 19, 8, 2, 82],\n",
              " [1, 79, 5, 80, 12, 81, 10, 28, 38, 2, 19, 8, 2, 82, 45],\n",
              " [1, 79, 5, 80, 12, 81, 10, 28, 38, 2, 19, 8, 2, 82, 45, 12],\n",
              " [1, 79, 5, 80, 12, 81, 10, 28, 38, 2, 19, 8, 2, 82, 45, 12, 20],\n",
              " [3, 30],\n",
              " [3, 30, 15],\n",
              " [3, 30, 15, 83],\n",
              " [3, 30, 15, 83, 18],\n",
              " [3, 30, 15, 83, 18, 84],\n",
              " [1, 13],\n",
              " [1, 13, 85],\n",
              " [1, 13, 85, 86],\n",
              " [1, 13, 85, 86, 16],\n",
              " [1, 13, 85, 86, 16, 21],\n",
              " [1, 13, 85, 86, 16, 21, 87],\n",
              " [1, 13, 85, 86, 16, 21, 87, 88],\n",
              " [1, 13, 85, 86, 16, 21, 87, 88, 89],\n",
              " [1, 13, 85, 86, 16, 21, 87, 88, 89, 90],\n",
              " [1, 13, 85, 86, 16, 21, 87, 88, 89, 90, 2],\n",
              " [1, 13, 85, 86, 16, 21, 87, 88, 89, 90, 2, 4],\n",
              " [1, 13, 85, 86, 16, 21, 87, 88, 89, 90, 2, 4, 91],\n",
              " [1, 13, 85, 86, 16, 21, 87, 88, 89, 90, 2, 4, 91, 92],\n",
              " [1, 13, 85, 86, 16, 21, 87, 88, 89, 90, 2, 4, 91, 92, 16],\n",
              " [1, 13, 85, 86, 16, 21, 87, 88, 89, 90, 2, 4, 91, 92, 16, 93],\n",
              " [1, 13, 85, 86, 16, 21, 87, 88, 89, 90, 2, 4, 91, 92, 16, 93, 94],\n",
              " [3, 95],\n",
              " [3, 95, 9],\n",
              " [3, 95, 9, 11],\n",
              " [3, 95, 9, 11, 4],\n",
              " [3, 95, 9, 11, 4, 1],\n",
              " [3, 95, 9, 11, 4, 1, 46],\n",
              " [3, 95, 9, 11, 4, 1, 46, 17],\n",
              " [1, 96],\n",
              " [1, 96, 17],\n",
              " [1, 96, 17, 11],\n",
              " [1, 96, 17, 11, 97],\n",
              " [1, 96, 17, 11, 97, 5],\n",
              " [1, 96, 17, 11, 97, 5, 47],\n",
              " [1, 96, 17, 11, 97, 5, 47, 48],\n",
              " [1, 96, 17, 11, 97, 5, 47, 48, 49],\n",
              " [1, 96, 17, 11, 97, 5, 47, 48, 49, 98],\n",
              " [1, 96, 17, 11, 97, 5, 47, 48, 49, 98, 99],\n",
              " [1, 96, 17, 11, 97, 5, 47, 48, 49, 98, 99, 50],\n",
              " [1, 96, 17, 11, 97, 5, 47, 48, 49, 98, 99, 50, 51],\n",
              " [1, 96, 17, 11, 97, 5, 47, 48, 49, 98, 99, 50, 51, 2],\n",
              " [1, 96, 17, 11, 97, 5, 47, 48, 49, 98, 99, 50, 51, 2, 100],\n",
              " [1, 96, 17, 11, 97, 5, 47, 48, 49, 98, 99, 50, 51, 2, 100, 31],\n",
              " [8, 101],\n",
              " [3, 41],\n",
              " [3, 41, 102],\n",
              " [3, 41, 102, 7],\n",
              " [3, 41, 102, 7, 1],\n",
              " [3, 41, 102, 7, 1, 103],\n",
              " [1, 104],\n",
              " [1, 104, 14],\n",
              " [1, 104, 14, 29],\n",
              " [1, 104, 14, 29, 42],\n",
              " [1, 104, 14, 29, 42, 2],\n",
              " [1, 104, 14, 29, 42, 2, 4],\n",
              " [1, 104, 14, 29, 42, 2, 4, 8],\n",
              " [1, 104, 14, 29, 42, 2, 4, 8, 14],\n",
              " [1, 104, 14, 29, 42, 2, 4, 8, 14, 2],\n",
              " [1, 104, 14, 29, 42, 2, 4, 8, 14, 2, 6],\n",
              " [3, 19],\n",
              " [3, 19, 8],\n",
              " [3, 19, 8, 52],\n",
              " [3, 19, 8, 52, 13],\n",
              " [3, 19, 8, 52, 13, 1],\n",
              " [3, 19, 8, 52, 13, 1, 39],\n",
              " [1, 105],\n",
              " [1, 105, 29],\n",
              " [1, 105, 29, 22],\n",
              " [1, 105, 29, 22, 106],\n",
              " [1, 105, 29, 22, 106, 43],\n",
              " [1, 105, 29, 22, 106, 43, 107],\n",
              " [1, 105, 29, 22, 106, 43, 107, 28],\n",
              " [1, 105, 29, 22, 106, 43, 107, 28, 108],\n",
              " [1, 105, 29, 22, 106, 43, 107, 28, 108, 2],\n",
              " [1, 105, 29, 22, 106, 43, 107, 28, 108, 2, 109],\n",
              " [1, 105, 29, 22, 106, 43, 107, 28, 108, 2, 109, 110],\n",
              " [1, 105, 29, 22, 106, 43, 107, 28, 108, 2, 109, 110, 111],\n",
              " [1, 105, 29, 22, 106, 43, 107, 28, 108, 2, 109, 110, 111, 112],\n",
              " [1, 105, 29, 22, 106, 43, 107, 28, 108, 2, 109, 110, 111, 112, 113],\n",
              " [7, 1],\n",
              " [7, 1, 53],\n",
              " [7, 1, 53, 6],\n",
              " [7, 1, 53, 6, 114],\n",
              " [1, 4],\n",
              " [1, 4, 115],\n",
              " [1, 4, 115, 21],\n",
              " [1, 4, 115, 21, 116],\n",
              " [1, 4, 115, 21, 116, 9],\n",
              " [1, 4, 115, 21, 116, 9, 117],\n",
              " [1, 4, 115, 21, 116, 9, 117, 6],\n",
              " [1, 4, 115, 21, 116, 9, 117, 6, 118],\n",
              " [1, 4, 115, 21, 116, 9, 117, 6, 118, 2],\n",
              " [1, 4, 115, 21, 116, 9, 117, 6, 118, 2, 23],\n",
              " [1, 4, 115, 21, 116, 9, 117, 6, 118, 2, 23, 32],\n",
              " [1, 4, 115, 21, 116, 9, 117, 6, 118, 2, 23, 32, 24],\n",
              " [3, 30],\n",
              " [3, 30, 15],\n",
              " [3, 30, 15, 119],\n",
              " [3, 30, 15, 119, 10],\n",
              " [3, 30, 15, 119, 10, 8],\n",
              " [1, 120],\n",
              " [1, 120, 121],\n",
              " [1, 120, 121, 24],\n",
              " [1, 120, 121, 24, 54],\n",
              " [1, 120, 121, 24, 54, 55],\n",
              " [1, 120, 121, 24, 54, 55, 56],\n",
              " [1, 120, 121, 24, 54, 55, 56, 2],\n",
              " [1, 120, 121, 24, 54, 55, 56, 2, 23],\n",
              " [1, 120, 121, 24, 54, 55, 56, 2, 23, 57],\n",
              " [1, 120, 121, 24, 54, 55, 56, 2, 23, 57, 122],\n",
              " [1, 120, 121, 24, 54, 55, 56, 2, 23, 57, 122, 57],\n",
              " [1, 120, 121, 24, 54, 55, 56, 2, 23, 57, 122, 57, 123],\n",
              " [1, 120, 121, 24, 54, 55, 56, 2, 23, 57, 122, 57, 123, 9],\n",
              " [1, 120, 121, 24, 54, 55, 56, 2, 23, 57, 122, 57, 123, 9, 52],\n",
              " [3, 124],\n",
              " [3, 124, 11],\n",
              " [3, 124, 11, 13],\n",
              " [3, 124, 11, 13, 1],\n",
              " [3, 124, 11, 13, 1, 40],\n",
              " [125, 9],\n",
              " [125, 9, 15],\n",
              " [125, 9, 15, 11],\n",
              " [125, 9, 15, 11, 126],\n",
              " [49, 127],\n",
              " [49, 127, 128],\n",
              " [47, 48],\n",
              " [47, 48, 129],\n",
              " [47, 48, 129, 130],\n",
              " [50, 51],\n",
              " [50, 51, 131],\n",
              " [50, 51, 131, 132],\n",
              " [50, 51, 131, 132, 133],\n",
              " [50, 51, 131, 132, 133, 17],\n",
              " [50, 51, 131, 132, 133, 17, 21],\n",
              " [50, 51, 131, 132, 133, 17, 21, 134],\n",
              " [50, 51, 131, 132, 133, 17, 21, 134, 135],\n",
              " [50, 51, 131, 132, 133, 17, 21, 134, 135, 136],\n",
              " [50, 51, 131, 132, 133, 17, 21, 134, 135, 136, 137],\n",
              " [31, 10],\n",
              " [31, 10, 58],\n",
              " [31, 10, 58, 59],\n",
              " [31, 10, 58, 59, 2],\n",
              " [31, 10, 58, 59, 2, 60],\n",
              " [31, 10, 58, 59, 2, 60, 33],\n",
              " [3, 4],\n",
              " [3, 4, 15],\n",
              " [3, 4, 15, 61],\n",
              " [3, 4, 15, 61, 138],\n",
              " [1, 139],\n",
              " [1, 139, 10],\n",
              " [1, 139, 10, 25],\n",
              " [1, 139, 10, 25, 35],\n",
              " [1, 139, 10, 25, 35, 61],\n",
              " [1, 139, 10, 25, 35, 61, 140],\n",
              " [1, 139, 10, 25, 35, 61, 140, 25],\n",
              " [1, 139, 10, 25, 35, 61, 140, 25, 141],\n",
              " [1, 139, 10, 25, 35, 61, 140, 25, 141, 142],\n",
              " [1, 139, 10, 25, 35, 61, 140, 25, 141, 142, 21],\n",
              " [1, 139, 10, 25, 35, 61, 140, 25, 141, 142, 21, 143],\n",
              " [1, 139, 10, 25, 35, 61, 140, 25, 141, 142, 21, 143, 144],\n",
              " [1, 139, 10, 25, 35, 61, 140, 25, 141, 142, 21, 143, 144, 145],\n",
              " [1, 139, 10, 25, 35, 61, 140, 25, 141, 142, 21, 143, 144, 145, 9],\n",
              " [1, 139, 10, 25, 35, 61, 140, 25, 141, 142, 21, 143, 144, 145, 9, 146],\n",
              " [1, 139, 10, 25, 35, 61, 140, 25, 141, 142, 21, 143, 144, 145, 9, 146, 147],\n",
              " [3, 20],\n",
              " [3, 20, 148],\n",
              " [3, 20, 148, 4],\n",
              " [3, 20, 148, 4, 1],\n",
              " [3, 20, 148, 4, 1, 46],\n",
              " [3, 20, 148, 4, 1, 46, 17],\n",
              " [1, 4],\n",
              " [1, 4, 149],\n",
              " [1, 4, 149, 9],\n",
              " [1, 4, 149, 9, 150],\n",
              " [1, 4, 149, 9, 150, 12],\n",
              " [1, 4, 149, 9, 150, 12, 20],\n",
              " [1, 4, 149, 9, 150, 12, 20, 151],\n",
              " [1, 4, 149, 9, 150, 12, 20, 151, 152],\n",
              " [1, 4, 149, 9, 150, 12, 20, 151, 152, 153],\n",
              " [1, 4, 149, 9, 150, 12, 20, 151, 152, 153, 154],\n",
              " [1, 4, 149, 9, 150, 12, 20, 151, 152, 153, 154, 155],\n",
              " [156, 18],\n",
              " [3, 4],\n",
              " [3, 4, 1],\n",
              " [3, 4, 1, 157],\n",
              " [3, 4, 1, 157, 62],\n",
              " [3, 4, 1, 157, 62, 10],\n",
              " [3, 4, 1, 157, 62, 10, 18],\n",
              " [1, 4],\n",
              " [1, 4, 62],\n",
              " [1, 4, 62, 14],\n",
              " [1, 4, 62, 14, 6],\n",
              " [1, 4, 62, 14, 6, 63],\n",
              " [1, 4, 62, 14, 6, 63, 60],\n",
              " [1, 4, 62, 14, 6, 63, 60, 33],\n",
              " [1, 4, 62, 14, 6, 63, 60, 33, 158],\n",
              " [1, 4, 62, 14, 6, 63, 60, 33, 158, 59],\n",
              " [1, 4, 62, 14, 6, 63, 60, 33, 158, 59, 159],\n",
              " [1, 4, 62, 14, 6, 63, 60, 33, 158, 59, 159, 160],\n",
              " [1, 4, 62, 14, 6, 63, 60, 33, 158, 59, 159, 160, 2],\n",
              " [1, 4, 62, 14, 6, 63, 60, 33, 158, 59, 159, 160, 2, 58],\n",
              " [3, 161],\n",
              " [3, 161, 7],\n",
              " [3, 161, 7, 1],\n",
              " [3, 161, 7, 1, 162],\n",
              " [3, 161, 7, 1, 162, 32],\n",
              " [3, 161, 7, 1, 162, 32, 64],\n",
              " [3, 161, 7, 1, 162, 32, 64, 16],\n",
              " [1, 23],\n",
              " [1, 23, 55],\n",
              " [1, 23, 55, 64],\n",
              " [1, 23, 55, 64, 16],\n",
              " [1, 23, 55, 64, 16, 163],\n",
              " [1, 23, 55, 64, 16, 163, 65],\n",
              " [1, 23, 55, 64, 16, 163, 65, 164],\n",
              " [1, 23, 55, 64, 16, 163, 65, 164, 165],\n",
              " [1, 23, 55, 64, 16, 163, 65, 164, 165, 166],\n",
              " [1, 23, 55, 64, 16, 163, 65, 164, 165, 166, 167],\n",
              " [1, 23, 55, 64, 16, 163, 65, 164, 165, 166, 167, 33],\n",
              " [1, 23, 55, 64, 16, 163, 65, 164, 165, 166, 167, 33, 168],\n",
              " [1, 23, 55, 64, 16, 163, 65, 164, 165, 166, 167, 33, 168, 169],\n",
              " [1, 23, 55, 64, 16, 163, 65, 164, 165, 166, 167, 33, 168, 169, 2],\n",
              " [1, 23, 55, 64, 16, 163, 65, 164, 165, 166, 167, 33, 168, 169, 2, 170],\n",
              " [1, 23, 55, 64, 16, 163, 65, 164, 165, 166, 167, 33, 168, 169, 2, 170, 171],\n",
              " [172, 173],\n",
              " [174, 7],\n",
              " [174, 7, 1],\n",
              " [174, 7, 1, 175],\n",
              " [174, 7, 1, 175, 25],\n",
              " [174, 7, 1, 175, 25, 176],\n",
              " [1, 177],\n",
              " [1, 177, 178],\n",
              " [1, 177, 178, 179],\n",
              " [1, 177, 178, 179, 180],\n",
              " [1, 177, 178, 179, 180, 22],\n",
              " [1, 177, 178, 179, 180, 22, 181],\n",
              " [1, 177, 178, 179, 180, 22, 181, 6],\n",
              " [1, 177, 178, 179, 180, 22, 181, 6, 53],\n",
              " [1, 177, 178, 179, 180, 22, 181, 6, 53, 182],\n",
              " [1, 177, 178, 179, 180, 22, 181, 6, 53, 182, 183],\n",
              " [1, 177, 178, 179, 180, 22, 181, 6, 53, 182, 183, 184],\n",
              " [1, 177, 178, 179, 180, 22, 181, 6, 53, 182, 183, 184, 2],\n",
              " [1, 177, 178, 179, 180, 22, 181, 6, 53, 182, 183, 184, 2, 185],\n",
              " [1, 177, 178, 179, 180, 22, 181, 6, 53, 182, 183, 184, 2, 185, 186],\n",
              " [7, 1],\n",
              " [7, 1, 65],\n",
              " [7, 1, 65, 187],\n",
              " [188, 1],\n",
              " [188, 1, 189],\n",
              " [188, 1, 189, 190],\n",
              " [188, 1, 189, 190, 26],\n",
              " [188, 1, 189, 190, 26, 5],\n",
              " [188, 1, 189, 190, 26, 5, 66],\n",
              " [188, 1, 189, 190, 26, 5, 66, 191],\n",
              " [188, 1, 189, 190, 26, 5, 66, 191, 6],\n",
              " [188, 1, 189, 190, 26, 5, 66, 191, 6, 192],\n",
              " [188, 1, 189, 190, 26, 5, 66, 191, 6, 192, 193],\n",
              " [188, 1, 189, 190, 26, 5, 66, 191, 6, 192, 193, 194],\n",
              " [188, 1, 189, 190, 26, 5, 66, 191, 6, 192, 193, 194, 195],\n",
              " [188, 1, 189, 190, 26, 5, 66, 191, 6, 192, 193, 194, 195, 196],\n",
              " [188, 1, 189, 190, 26, 5, 66, 191, 6, 192, 193, 194, 195, 196, 197],\n",
              " [188, 1, 189, 190, 26, 5, 66, 191, 6, 192, 193, 194, 195, 196, 197, 198],\n",
              " [188, 1, 189, 190, 26, 5, 66, 191, 6, 192, 193, 194, 195, 196, 197, 198, 5],\n",
              " [188,\n",
              "  1,\n",
              "  189,\n",
              "  190,\n",
              "  26,\n",
              "  5,\n",
              "  66,\n",
              "  191,\n",
              "  6,\n",
              "  192,\n",
              "  193,\n",
              "  194,\n",
              "  195,\n",
              "  196,\n",
              "  197,\n",
              "  198,\n",
              "  5,\n",
              "  66],\n",
              " [188,\n",
              "  1,\n",
              "  189,\n",
              "  190,\n",
              "  26,\n",
              "  5,\n",
              "  66,\n",
              "  191,\n",
              "  6,\n",
              "  192,\n",
              "  193,\n",
              "  194,\n",
              "  195,\n",
              "  196,\n",
              "  197,\n",
              "  198,\n",
              "  5,\n",
              "  66,\n",
              "  199],\n",
              " [200, 201],\n",
              " [3, 4],\n",
              " [3, 4, 1],\n",
              " [3, 4, 1, 202],\n",
              " [3, 4, 1, 202, 67],\n",
              " [3, 4, 1, 202, 67, 27],\n",
              " [1, 4],\n",
              " [1, 4, 67],\n",
              " [1, 4, 67, 27],\n",
              " [1, 4, 67, 27, 37],\n",
              " [1, 4, 67, 27, 37, 22],\n",
              " [1, 4, 67, 27, 37, 22, 6],\n",
              " [1, 4, 67, 27, 37, 22, 6, 2],\n",
              " [1, 4, 67, 27, 37, 22, 6, 2, 203],\n",
              " [1, 4, 67, 27, 37, 22, 6, 2, 203, 204],\n",
              " [1, 4, 67, 27, 37, 22, 6, 2, 203, 204, 205],\n",
              " [1, 4, 67, 27, 37, 22, 6, 2, 203, 204, 205, 11],\n",
              " [3, 68],\n",
              " [3, 68, 9],\n",
              " [3, 68, 9, 24],\n",
              " [3, 68, 9, 24, 7],\n",
              " [3, 68, 9, 24, 7, 1],\n",
              " [3, 68, 9, 24, 7, 1, 69],\n",
              " [1, 23],\n",
              " [56, 207],\n",
              " [208, 209],\n",
              " [210, 211],\n",
              " [212, 44],\n",
              " [3, 7],\n",
              " [3, 7, 1],\n",
              " [3, 7, 1, 213],\n",
              " [3, 7, 1, 213, 5],\n",
              " [3, 7, 1, 213, 5, 214],\n",
              " [3, 7, 1, 213, 5, 214, 215],\n",
              " [3, 7, 1, 213, 5, 214, 215, 36],\n",
              " [1, 54],\n",
              " [5, 45],\n",
              " [5, 45, 216],\n",
              " [5, 45, 216, 6],\n",
              " [5, 45, 216, 6, 63],\n",
              " [5, 217],\n",
              " [5, 217, 22],\n",
              " [5, 217, 22, 218],\n",
              " [5, 219],\n",
              " [5, 219, 220],\n",
              " [5, 219, 220, 221],\n",
              " [5, 222],\n",
              " [5, 222, 25],\n",
              " [5, 222, 25, 223],\n",
              " [5, 224],\n",
              " [5, 224, 17],\n",
              " [5, 224, 17, 12],\n",
              " [5, 224, 17, 12, 20],\n",
              " [5, 225],\n",
              " [5, 225, 226],\n",
              " [227, 228],\n",
              " [3, 229],\n",
              " [3, 229, 7],\n",
              " [3, 229, 7, 1],\n",
              " [3, 229, 7, 1, 69],\n",
              " [3, 229, 7, 1, 69, 16],\n",
              " [3, 229, 7, 1, 69, 16, 26],\n",
              " [1, 230],\n",
              " [1, 230, 5],\n",
              " [1, 230, 5, 231],\n",
              " [1, 230, 5, 231, 26],\n",
              " [1, 230, 5, 231, 26, 232],\n",
              " [3, 68],\n",
              " [3, 68, 9],\n",
              " [3, 68, 9, 233],\n",
              " [3, 68, 9, 233, 7],\n",
              " [3, 68, 9, 233, 7, 1],\n",
              " [3, 68, 9, 233, 7, 1, 234],\n",
              " [3, 68, 9, 233, 7, 1, 234, 235],\n",
              " [3, 68, 9, 233, 7, 1, 234, 235, 26],\n",
              " [1, 236],\n",
              " [237, 24],\n",
              " [238, 239],\n",
              " [240, 241],\n",
              " [242, 243],\n",
              " [31, 244]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len=max([len(x) for x in input_sequences])"
      ],
      "metadata": {
        "id": "6DTJ54MfPh3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC2DufOIUtVp",
        "outputId": "39cf688e-54cd-4bb8-924e-103e6c1ecbbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input=pad_sequences(input_sequences,maxlen=max_len,padding='pre')"
      ],
      "metadata": {
        "id": "GqMRTxvfP5gX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld6DpqU5Q4Hx",
        "outputId": "cdfb5173-2e73-4f9c-b49f-667fd574d539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,  27,   1],\n",
              "       [  0,   0,   0, ...,   0,  34,   4],\n",
              "       [  0,   0,   0, ...,  34,   4,   1],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,   0, 240, 241],\n",
              "       [  0,   0,   0, ...,   0, 242, 243],\n",
              "       [  0,   0,   0, ...,   0,  31, 244]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=padded_input[:,:-1]"
      ],
      "metadata": {
        "id": "QROJUCiWQVRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=padded_input[:,-1]"
      ],
      "metadata": {
        "id": "bdcNOH7uQzaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZauWJlNRBjh",
        "outputId": "6227a497-2d81-41cb-f126-f036bd6eac99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(409, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Onz65Z0Rzwh",
        "outputId": "fe156bcb-b9c8-4a66-8e49-6c75a1e82971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(409,)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y=to_categorical(y,num_classes=len(tokenizer.word_index)+1)"
      ],
      "metadata": {
        "id": "XPjFAnuJR1Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqajLBQaUYch",
        "outputId": "640f1b38-101c-4d8e-df42-eb355b88ae2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "244"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph2TjakrSgXD",
        "outputId": "5b2a0e5e-8283-42a7-a483-8de1a23dd26b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(409, 245)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Embedding,LSTM"
      ],
      "metadata": {
        "id": "U3Rhs5QhSpM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(input_dim=245, output_dim=100, input_shape=(19,)))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(245,activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtUo9MFyT-W9",
        "outputId": "8f3836bb-6cfb-4b4b-8b5d-c8d2099ae5ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:100: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "IzGsfPb2Uv85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "TQOk6s90U_3r",
        "outputId": "d808e328-74bf-49d2-c82f-c50db5e097e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m24,500\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m150,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m245\u001b[0m)            │        \u001b[38;5;34m36,995\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,500</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">245</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,995</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m212,095\u001b[0m (828.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">212,095</span> (828.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m212,095\u001b[0m (828.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">212,095</span> (828.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9TMrk92VBQm",
        "outputId": "be7d2eda-ed4c-4e82-ddad-a56c0902c491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.0414 - loss: 5.4939\n",
            "Epoch 2/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0292 - loss: 5.3129\n",
            "Epoch 3/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0532 - loss: 5.1040\n",
            "Epoch 4/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0838 - loss: 5.0875\n",
            "Epoch 5/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0912 - loss: 4.9877\n",
            "Epoch 6/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0760 - loss: 4.8833\n",
            "Epoch 7/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0795 - loss: 4.8510\n",
            "Epoch 8/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0902 - loss: 4.6920\n",
            "Epoch 9/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0963 - loss: 4.5912\n",
            "Epoch 10/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0823 - loss: 4.5697\n",
            "Epoch 11/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0989 - loss: 4.3911\n",
            "Epoch 12/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1034 - loss: 4.2908\n",
            "Epoch 13/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1246 - loss: 4.1306\n",
            "Epoch 14/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1155 - loss: 4.0700\n",
            "Epoch 15/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1169 - loss: 3.9025\n",
            "Epoch 16/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1577 - loss: 3.7809\n",
            "Epoch 17/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1680 - loss: 3.6279\n",
            "Epoch 18/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2109 - loss: 3.4294\n",
            "Epoch 19/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2213 - loss: 3.4136\n",
            "Epoch 20/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2333 - loss: 3.3116\n",
            "Epoch 21/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2591 - loss: 3.1534\n",
            "Epoch 22/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3277 - loss: 3.0002\n",
            "Epoch 23/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2909 - loss: 2.9716\n",
            "Epoch 24/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3503 - loss: 2.7965\n",
            "Epoch 25/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4236 - loss: 2.6169\n",
            "Epoch 26/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4240 - loss: 2.5382\n",
            "Epoch 27/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4692 - loss: 2.4855\n",
            "Epoch 28/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4772 - loss: 2.3563\n",
            "Epoch 29/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5545 - loss: 2.2470\n",
            "Epoch 30/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6047 - loss: 2.0967\n",
            "Epoch 31/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6110 - loss: 2.0549\n",
            "Epoch 32/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6278 - loss: 1.9908\n",
            "Epoch 33/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6542 - loss: 1.9010\n",
            "Epoch 34/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6619 - loss: 1.8101\n",
            "Epoch 35/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7014 - loss: 1.7404\n",
            "Epoch 36/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7389 - loss: 1.6656\n",
            "Epoch 37/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7505 - loss: 1.5407\n",
            "Epoch 38/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7535 - loss: 1.5116\n",
            "Epoch 39/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7961 - loss: 1.4234\n",
            "Epoch 40/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8108 - loss: 1.3417\n",
            "Epoch 41/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8020 - loss: 1.2671\n",
            "Epoch 42/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8003 - loss: 1.2954\n",
            "Epoch 43/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8318 - loss: 1.1696\n",
            "Epoch 44/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8393 - loss: 1.1362\n",
            "Epoch 45/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8319 - loss: 1.1463\n",
            "Epoch 46/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8592 - loss: 1.0173\n",
            "Epoch 47/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8397 - loss: 1.0549\n",
            "Epoch 48/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8746 - loss: 0.9535\n",
            "Epoch 49/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8457 - loss: 0.9637\n",
            "Epoch 50/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8428 - loss: 0.9742\n",
            "Epoch 51/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8570 - loss: 0.8668\n",
            "Epoch 52/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8768 - loss: 0.8641\n",
            "Epoch 53/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8579 - loss: 0.8641\n",
            "Epoch 54/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8603 - loss: 0.8060\n",
            "Epoch 55/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8907 - loss: 0.7276\n",
            "Epoch 56/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8868 - loss: 0.7421\n",
            "Epoch 57/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8876 - loss: 0.7237\n",
            "Epoch 58/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8602 - loss: 0.7322\n",
            "Epoch 59/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8710 - loss: 0.7023\n",
            "Epoch 60/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8821 - loss: 0.6320\n",
            "Epoch 61/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8725 - loss: 0.6296\n",
            "Epoch 62/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8689 - loss: 0.6382\n",
            "Epoch 63/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8722 - loss: 0.6487\n",
            "Epoch 64/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8818 - loss: 0.6109\n",
            "Epoch 65/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8836 - loss: 0.5715\n",
            "Epoch 66/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8715 - loss: 0.6278\n",
            "Epoch 67/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8808 - loss: 0.5694\n",
            "Epoch 68/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8692 - loss: 0.5993\n",
            "Epoch 69/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8733 - loss: 0.5758\n",
            "Epoch 70/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8650 - loss: 0.5671\n",
            "Epoch 71/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8864 - loss: 0.5108\n",
            "Epoch 72/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8930 - loss: 0.5080\n",
            "Epoch 73/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8631 - loss: 0.5024\n",
            "Epoch 74/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8931 - loss: 0.4824\n",
            "Epoch 75/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8919 - loss: 0.4561\n",
            "Epoch 76/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9023 - loss: 0.4585\n",
            "Epoch 77/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8754 - loss: 0.5063\n",
            "Epoch 78/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8773 - loss: 0.4946\n",
            "Epoch 79/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8926 - loss: 0.4361\n",
            "Epoch 80/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8594 - loss: 0.5101\n",
            "Epoch 81/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9073 - loss: 0.3942\n",
            "Epoch 82/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9040 - loss: 0.4003\n",
            "Epoch 83/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9008 - loss: 0.3874\n",
            "Epoch 84/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8962 - loss: 0.4200\n",
            "Epoch 85/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9151 - loss: 0.3521\n",
            "Epoch 86/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8871 - loss: 0.4085\n",
            "Epoch 87/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8892 - loss: 0.3867\n",
            "Epoch 88/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8856 - loss: 0.3463\n",
            "Epoch 89/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9078 - loss: 0.3677\n",
            "Epoch 90/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8904 - loss: 0.3932\n",
            "Epoch 91/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8958 - loss: 0.3833\n",
            "Epoch 92/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8895 - loss: 0.3651\n",
            "Epoch 93/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8828 - loss: 0.3981\n",
            "Epoch 94/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8563 - loss: 0.4573\n",
            "Epoch 95/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8835 - loss: 0.4063\n",
            "Epoch 96/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8874 - loss: 0.3686\n",
            "Epoch 97/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8918 - loss: 0.3721\n",
            "Epoch 98/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8698 - loss: 0.3906\n",
            "Epoch 99/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8901 - loss: 0.3782\n",
            "Epoch 100/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8893 - loss: 0.3610\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cfcf57bad80>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "text = \"is\"\n",
        "\n",
        "for i in range(10):\n",
        "    # tokenize\n",
        "    token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "\n",
        "    # padding\n",
        "    padded_token_text = pad_sequences([token_text], maxlen=19, padding='pre')\n",
        "\n",
        "pos=np.argmax(model.predict(padded_token_text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hiz1ldGjXylI",
        "outputId": "14b0a0ae-5cee-42b9-bcc0-5c544b6aa185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word,index in tokenizer.word_index.items():\n",
        "  if index== pos:\n",
        "    print(word)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gqvy6yn5ZPD3",
        "outputId": "7ae7be64-545c-4bd3-b7ae-20d0d68bb9e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yash\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hcEIxSl4aWfR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}